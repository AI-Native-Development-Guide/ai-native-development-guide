<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Testings on GitHub Copilot Patterns &amp; Exercises</title><link>/ja/testing/</link><description>Recent content in Testings on GitHub Copilot Patterns &amp; Exercises</description><generator>Hugo -- gohugo.io</generator><language>ja</language><atom:link href="/ja/testing/index.xml" rel="self" type="application/rss+xml"/><item><title>テストコード生成の方法を指定する</title><link>/ja/testing/specify-test-valiation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/ja/testing/specify-test-valiation/</guid><description>テストコード生成の方法を指定する Description テストに関する指示を具体的に示すことは、必要なシナリオをすべてカバーする良い方法です。&amp;ldquo;ユニットテストを追加する&amp;quot;といった曖昧な指示ではなく、テストフレームワークや生成するケースの数などの具体的な詳細を提供することができます。GitHub Copilotのようなツールを活用する際には、「JunitとMockitoを使用してユニットテストを追加し、少なくとも10種類の有効な/無効な入力の組み合わせをテストする」といった指定を行うことで、より正確で包括的な結果を得ることができます。
Example Junit と Mockito を使用してテストコードを生成する場合、次のプロンプトを GitHub Copilot に提供できます:
// JunitとMockitoを使用してユニットテストを追加する // 少なくとも10種類の有効な/無効な入力の組み合わせをテストする @Test public void validateInput() { // ここにコードを記述 } Exercise エクササイズ1: Junit を使用して、異なる3つの有効な入力で単純なメソッドをテストするユニットテストを書いてみましょう。 エクササイズ2: ユニットテストを拡張して、3つの異なる無効な入力を含め、例外が適切に処理されることを確認します。 Checklist for Further Learning コード内のすべての重要なパスをテストする方法はどのように確保できるでしょうか? テストが必ず失敗するようにテストコードを書くことはできますか? コードベースが進化するにつれてテストを維持するためにどのような戦略をとることができますか?</description></item><item><title>ユニットテストの作成</title><link>/ja/testing/creating-unit-tests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/ja/testing/creating-unit-tests/</guid><description>ユニットテストの作成 Description テストはソフトウェア開発プロセスの基本的な部分であり、コードが設計どおりであり、意図した通りに動作することを確認します。システムの個々のコンポーネントをテストするユニットテストの作成は、チャレンジングで時間のかかる作業です。GitHub Copilotを使用すると、このプロセスがより効率的になります。開発者のAliceさんがGitHub Copilotをどのように活用してアプリケーションのユニットテストを記述し、作業量を減少させ、効率を向上させるかを探ってみましょう。 このパターンは、機能テストや API テストにも適用可能です。
Example 徹底的にテストする必要のある JavaScript の関数に取り組んでいます。GitHub Copilotの助けを借りて、必要なユニットテストを素早く生成できます。
以下は、テストしたいシンプルな関数です:
function add(x, y) { return x + y; } そして、GitHub Copilotの支援を受けてユニットテストを作成する方法は次のとおりです:
const assert = require(&amp;#39;assert&amp;#39;); describe(&amp;#39;add関数&amp;#39;, () =&amp;gt; { it(&amp;#39;2つの数値を正しく加算する必要があります&amp;#39;, () =&amp;gt; { assert.equal(add(2, 3), 5); }); }); Exercise エクササイズ1: GitHub Copilotを使用して2つの数値を掛ける関数のユニットテストを作成してください。 エクササイズ2: Copilotを活用して、nullやundefinedの値を処理するなど、さまざまなエッジケースのテストスイートを作成してください。 エクササイズ3: 現在のプロジェクトを振り返り、テストが不足しているコードの部分を特定し、Copilotを使用してユニットテストを作成してください。 Checklist for Further Learning 自分のテストが包括的であり、すべての可能なシナリオをカバーしていることをどのように確認できますか? GitHub Copilot がシナリオを全くカバーしなかった際にどのようなプロンプトを追加しますか? 他の種類のテスト(E2Eテスト、統合テスト、機能テストなど) に対して、GitHub Copilot はどのように有益であり、それらを記述する際に GitHub Copilotはどのように支援できるか?</description></item><item><title>自然言語でテストケースを最初に記述する</title><link>/ja/testing/writing-test-cases-in-natural-language-first/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/ja/testing/writing-test-cases-in-natural-language-first/</guid><description>自然言語でテストケースを最初に記述する Description GitHub Copilotのような AI を活用したコード生成を行う際、AI に明確なコンテキストを提供せずに包括的なテストカバレッジを期待するのは難しいことです。その段階でコードでテストケースを記述しようとする代わりに、まず自然言語の記述を作成します。これにより、生成されたコードがすべての必要な基準を満たすことを確認することに焦点を当て、テストカバレッジを向上させることができます。
Example 以下は、自然言語でテストケースを記述する方法の例です。この方法を使用することで、コードを生成する前にさまざまなシナリオやエッジケースをカバーすることができます。
class TestMultiply(unittest.TestCase): def test_multiply(self): # 正数、負数、ゼロ、小数、非整数の入力など、さまざまなケースのテスト Exercise エクササイズ1: 三角形の面積を計算する関数に対して、自然言語のテストケースを記述してください。さまざまな入力シナリオとエッジケースを考慮してください。 エクササイズ2: エクササイズ1で記述した自然言語のテストケースから、GitHub Copilotを使用してコードを生成します。結果を分析します。 エクササイズ3: より複雑な関数（例: ソートアルゴリズム）に対して、自然言語を使用してテストスイートを作成します。さまざまな入力シナリオとエッジケースを考慮してください。 学習のためのチェックリスト コードを記述する前に自然言語でテストケースを記述する利点は何ですか? 自然言語で記述されたテストケースは、開発者と非技術的な関係者との協力をどのように改善できますか? このアプローチを使用する際の潜在的な課題は何であり、それらはどのように緩和できますか?</description></item><item><title>失敗ケースを最初に書く</title><link>/ja/testing/writing-failure-case-first/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/ja/testing/writing-failure-case-first/</guid><description>失敗ケースを最初に書く {% hint style=&amp;ldquo;info&amp;rdquo; %} 失敗ケースを最初に書くことは開発において重要なことではありますが、GitHub Copilotにテストケースを適切に提案させる方法について、ベストプラクティスを見つけ出す必要があります。 {% endhint %}
Description 開発サイクルにおいて、テストケースの作成は重要な側面です。GitHub Copilot を使用すると、実装を読み取り、それに応じてテストケースを生成するため、さらに便利になります。一方で GitHub Copilot は成功ケースの生成に非常に効果的ですが、失敗ケースを見落とさないようにすることが重要です。最初に失敗ケースを考慮すると、より堅牢なコードにつながることがあります。
Example これの重要性を示すために、2つの数値を割る関数を考えてみましょう。GitHub Copilot は、成功ケースをカバーするテストケースを提案するかもしれません。しかし、分母がゼロの場合はどうでしょうか？
def divide(a, b): return a / b # Failure test case def test_divide_by_zero(): # &amp;lt;YOUR CODE AND GITHUB COPILOT SUGGESTION HERE&amp;gt; Exerecise エクササイズ1: 2つの数字を掛ける関数を書き、成功ケースと失敗ケースの両方を含めてください（大きな数字の掛け算などのエッジケースを考慮してください） エクササイズ2: プロジェクト内の既存のコード片を分析し、欠落している失敗ケースを特定してください。これらのテストケースを書いてみましょう。 エクササイズ3: 次のプロジェクトでTDDのアプローチを実装し、実際の実装よりも先に失敗テストケースを書くようにし、これが開発プロセスにどのように影響するかを考えてみてください。 Checklist for Further Learning 最近のコードで全ての潜在的な失敗ケースを考慮しましたか？ テストスイートに一貫して失敗テストケースを含めていますか？ チームがテストケースの作成においてTDDのマインドセットを採用するように、どのように促進できますか？</description></item><item><title>必要な部分だけをテストする</title><link>/ja/testing/test-only-what-is-necessary/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/ja/testing/test-only-what-is-necessary/</guid><description>必要な部分だけをテストする {% hint style=&amp;ldquo;info&amp;rdquo; %} 不必要なテストケースを書く必要はありませんが、どのようなテストが必要かはチームによります。パターンとして具体化するには、より具体的な議論が必要です。 {% endhint %}
Description 高速なソフトウェア開発の時代において、効率的で有益なテストの記述はこれまで以上に重要です。GitHub Copilotを使用する際に、開発者はカバレッジを増やすために多くのテストコードを生成してしまうかもしれません。しかし、不必要なテストコードの生成は保守の負担や技術的な負債を引き起こす可能性があります。GitHub Copilotを使用してテストコードを書く際には必要な部分のみをテストする事が重要です。
Example 特定の関数に対して意味のあるテストを書くことに重点を置くことで、カバレッジを上げるために複数のテストを書く代わりに、意味のあるテストを書くことが重要です。
以下は不必要になりうるテストコードの例です:
セッターやゲッターのテスト 言語の機能のテスト フレームワークの機能のテスト 定数のテスト 同じロジックを持つ冗長なテスト 些細なロジックのテスト サードパーティのライブラリのテスト ロジックのないランダムな値のテスト カバレッジを増やすだけでなく、また価値を追加しない数多くのテストを追加するのではなく、必要なテストのみを追加します。
Exercise エクササイズ 1: 現在意味のないテストで過度にテストされているコードベース内の関数を特定し、必要なテストのみを含むようリファクタリングします。 エクササイズ 2: コードの重要な部分に新しいテストを書き、冗長性を避けて重要な側面に焦点を当てます。 エクササイズ 3: 現在のテストカバレッジを評価し、不可欠なカバレッジを失うことなくテストを削減できる領域を特定します。 Checklist for Further Learning 機能を確実に検証するテストを書いているか、それとも単にカバレッジを上げるためのテストを書いていますか? 書いているテストがプロジェクトに価値を提供し、保守の負担を増やすだけでないことをどのように確認できますか? 特に GitHub Copilot などのツールを使用する際、テストスイートをスリムで意味のあるものに保つためにどのような戦略を取り入れることができますか?</description></item></channel></rss>